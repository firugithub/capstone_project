Steps
1.Created 'card_member' and 'member_score' in HBASE
2.Created Hive mapping table for 'card_member' and 'member_score' named as 'card_member_hive' and 'member_score_hive'
3.Created 2 sqoop jobs for loading data from AWS RDS to 'card_member' and 'member_score' tables.
These sqoop jobs we will configure in scheduler job to run every 4 hr.
	

## Create member_score table in HBASE
create 'card_member' ,'card_member_details'

### sqoop job command to load data from AWS RDS to HBASE
sqoop job --create card_member_sqoop_job --meta-connect jdbc:hsqldb:hsql://ip-172-31-36-190.ec2.internal:16000/sqoop -- import 
--connect jdbc:mysql://upgradawsrds.cpclxrkdvwmz.us-east-1.rds.amazonaws.com/cred_financials_data --username upgraduser --password upgraduser --table card_member --columns "card_id,member_id,member_joining_dt,card_purchase_dt,country,city" --hbase-table card_member --column-family card_member_details --hbase-row-key card_id -m 1 --incremental append --check-column member_joining_dt --last-value



### sqoop command to load data from AWS RDS to HBASE
sqoop import --connect jdbc:mysql://upgradawsrds.cpclxrkdvwmz.us-east-1.rds.amazonaws.com/cred_financials_data --username upgraduser --password upgraduser --table card_member --columns "card_id,member_id,member_joining_dt,card_purchase_dt,country,city" --hbase-table card_member --column-family card_member_details --hbase-row-key card_id -m 1 


### Create mapping table in HIVE 
create external table card_member_hive(card_id string,member_id string,member_joining_dt timestamp,card_purchase_dt string,country string,city string)
STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler' WITH SERDEPROPERTIES 
("hbase.columns.mapping"=":key,card_member_details:member_id,card_member_details:member_joining_dt,card_member_details:card_purchase_dt,card_member_details:country,card_member_details:city") TBLPROPERTIES ("hbase.table.name"="card_member");
	
	
	
### Create member_score table in HBASE
create 'member_score' ,'member_score_detail'

### sqoop job command to load data from AWS RDS to HBASE
sqoop job --create member_score_sqoop_job --meta-connect jdbc:hsqldb:hsql://ip-172-31-36-190.ec2.internal:16000/sqoop -- import 
--connect jdbc:mysql://upgradawsrds.cpclxrkdvwmz.us-east-1.rds.amazonaws.com/cred_financials_data --username upgraduser --password upgraduser --table member_score --columns "member_id,score" --hbase-table member_score --column-family member_score_detail --hbase-row-key member_id -m 1	

### sqoop command to load data from AWS RDS to HBASE
sqoop import --connect jdbc:mysql://upgradawsrds.cpclxrkdvwmz.us-east-1.rds.amazonaws.com/cred_financials_data --username upgraduser --password upgraduser --table member_score --columns "member_id,score" --hbase-table member_score --column-family member_score_detail --hbase-row-key member_id -m 1

### Create mapping table in HIVE 
create external table member_score_hive(member_id string, score int )
STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler' WITH SERDEPROPERTIES 
("hbase.columns.mapping"=":key,member_score_detail:score") TBLPROPERTIES ("hbase.table.name"="member_score");

